# Методы обработки естественных языков 
## Практическая работа №5

### Цели и задачи:
Необходимо на основе результатов, полученных при выполнении Практической работы №4, расширить полученный семантический анализатор естественного языка средствами генерации осмысленного текста только на его основе. Используйте нейросети классов LSTM, а также методы sequence-to-secuence.  Внимание: допускается использовать генераторы только на основе шаблонов. Другие, в том числе гибридные подходы изучаются в следующем элементе практикума.

Программную реализацию необходимо разместить в любом открытом GIT-репозитории. В файле README необходимо привести инструкцию по сборке, развертыванию и использованию анализатора с примерами работы трех полученных семантических анализаторов (в том числе пользовательских данных), а также их сравнительное описание. Альтернативно - создать архив проекта (с документацией), разместить в облачном хранилище. Допустимые форматы: zip, tar.gz, 7z.
### Решение
В качестве данных для реализации сементического анализатора (LSA) было решено сгенерировать тексты, каждый из которых имеет позитивную, либо негативную окраску. В качестве реальной метки используется класс из первом практической - SentimentAnalysis.


### Результат:
Была обучения реккурентная нейронная сеть LSTM для генерации текстов на основе тональности. Примеры генераций (представлены в конце блокнота):
```
=== Генерация позитивного текста ===
<pos> i had a wonderful day everything went perfectly well all my expectations expectations expectations expectations

=== Генерация негативного текста ===
<neg> the was was nothing nothing complain about but nothing to praise praise praise expectations expectations

=== Ещё позитивный ===
<pos> i am incredibly happy with the results everything turned out amazing amazing nor bad out amazing amazing

=== Ещё негативный ===
<neg> this product was was and and didn't enjoy it at all my expectations expectations expectations expectations expectations
```

Как можем заметить модель научилась "триггерным" словам и использует их при генерации текста определенной тональности. Для позитивных это всевозможные прилагательные по типу wonderful, amazing, happy и тп. Для негативных - nothing, didn't enjoy.
Но, ввиду того, что текстов мало, модель не научилась правильно связывать слова.

### Формат текста
Тест должен находиться в файле data/train_texts.txt. Каждый новый текст с новой строки и пустой строкой между ними.

### Запуск
В файле main.ipynb представлена последовательная работа с наборами текстов. Выполняется полная предобработка текста и построение сементического анализатора естественного текста. 

- В удобном python окружении запустить:
```pip install -r requirements.txt```
- Скопировать свой текст в файл train_texts.txt (или создать этот файл, если отсутствует)
- Выполнить:
```jupyter notebook main.ipynb```